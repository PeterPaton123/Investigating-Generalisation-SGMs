Wasserstein distance for distributions

Doing computations on the samples is shite, motivates the need of the neural network

Implement and test the Milstein method, derive the solution for a geometric brownian motion

Monte carlo sampling for neural network not [-10, 10] linspace
Look why the Bts work, scaling coefficient of xt with time
Interacting SDE forward pass and try to derive the marginal pdf in backwards pass analytically, then implement

VAE
GAN
energy based models

latent diffusion
interacting SDEs for forward and backward pass (McLean Vlasov SDE)




Todo:

Verify the 
Verify pdf with plotting and histograms
Use neural network for score function in interacting case
Train on departmental GPUs


What is the idea behind interacting SDEs?
What is a diffusion model

Look at the Fokker Planke equation and relate it to Ornstein Ulhenbeck

Formalise the (matrix) derivation of the interacting SDEs
Gain an analytic solution to the multivariate Ornstein Ulhenbeck process
(If conditionals just use the fact that co variance in the initial samples is 0 except along the diagonal which is the variance of our mixture)
Use this analytic solution to solve the interacting SDE

Perhaps move on to the Bt case, and do some hyper parameter optimisation?

Catch-up:

Implement the forward pass of multivariate with n samples interferring
Compare the Milstein distance in t with the interferring and non-interferring case

Implement the backwards pass with an analytic score function
Implement the backwards pass with a neural network for the score function instead

Compare the milstein distance in t for both reverse cases 

Use Bi_ts as well and change them from b min to b max


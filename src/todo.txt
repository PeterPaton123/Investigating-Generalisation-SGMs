Wasserstein distance for distributions

Doing computations on the samples is shite, motivates the need of the neural network

Implement and test the Milstein method, derive the solution for a geometric brownian motion

Monte carlo sampling for neural network not [-10, 10] linspace
Look why the Bts work, scaling coefficient of xt with time
Interacting SDE forward pass and try to derive the marginal pdf in backwards pass analytically, then implement




VAE
GAN
energy based models

latent diffusion
interacting SDEs for forward and backward pass (McLean Vlasov SDE)




Todo:

Formalise the derivation of the interacting SDEs
Gain an analytic solution to the multivariate Ornstein Ulhenbeck process
(If conditionals just use the fact that co variance in the initial samples is 0 except along the diagonal which is the variance of our mixture)

Implement the forward pass of multivariate with n samples interferring
Compare the Milstein distance in t with the interferring and non-interferring case

Implement the backwards pass with an analytic score function
Implement the backwards pass with a neural network for the score function instead

Compare the milstein distance in t for both reverse cases 

Use Bi_ts as well and change them from b min to b max

